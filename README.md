# Rust vs. Python for ML: A Performance Benchmark

This repository contains a clean, simple benchmark suite for comparing the performance of Rust-based machine learning libraries against their established Python counterparts. The focus is on classical machine learning algorithms across different dataset sizes.

## ğŸ¯ Simple & Clean Benchmark Suite

### **Dataset-Centric Organization**

The benchmark suite is organized by dataset size for fair comparison:

- **ğŸŒ¼ Small Dataset**: Iris (150 samples, 4 features) - Fast iteration and development
- **ğŸ¦ Large Dataset**: Bank Marketing (41,188 samples, 20 features) - Production-scale performance

### **Library Coverage**

- **ğŸ Python**: scikit-learn (industry standard)
- **ğŸ¦€ Rust**: SmartCore and Linfa (emerging Rust ML libraries)

### **Algorithm Standardization**

All algorithms are standardized across libraries for fair comparison:
- **SVM**: Support Vector Machines (various kernels)
- **Decision Tree**: Tree-based classification
- **Random Forest**: Ensemble tree methods
- **Neural Network**: Multi-layer perceptrons

#### Quick Start

```bash
# Run all benchmarks (both datasets)
./run_benchmarks.sh

# Run single dataset benchmark
python3 scripts/benchmark_runner.py --dataset data/iris.csv --runs 5

# Run large dataset benchmark
python3 scripts/benchmark_runner.py --dataset data/bank-additional/bank-additional-full.csv --runs 3
```

## Repository Structure

```
rust-ml-benchmark/
â”œâ”€â”€ data/                        # Input datasets
â”‚   â”œâ”€â”€ iris.csv                 # ğŸŒ¼ Small dataset (150 samples)
â”‚   â””â”€â”€ bank-additional/         # ğŸ¦ Large dataset (41K samples)
â”œâ”€â”€ results/                     # Output reports and plots
â”œâ”€â”€ scripts/                     # Benchmark source code
â”‚   â”œâ”€â”€ benchmark_runner.py      # ğŸ¯ Main benchmark orchestrator
â”‚   â”œâ”€â”€ sklearn_runner.py        # ğŸ Python (scikit-learn) runner
â”‚   â”œâ”€â”€ smartcore_bencher/       # ğŸ¦€ SmartCore Rust benchmarks
â”‚   â””â”€â”€ linfa_bencher/           # ğŸ¦€ Linfa Rust benchmarks
â”œâ”€â”€ run_benchmarks.sh            # ğŸš€ One-command benchmark runner
â””â”€â”€ README.md                    # This file
```

### Benchmark Features

| Feature | Description |
|---------|-------------|
| **Dataset-Centric** | Organized by dataset size (small vs large) |
| **Algorithm Standardization** | Consistent naming across libraries |
| **Multiple Runs** | Statistical significance with warmup |
| **Resource Monitoring** | Memory usage tracking |
| **Fair Comparison** | Same algorithms compared across libraries |
| **Clean Output** | Simple reports and visualizations |

## How to Run

### Prerequisites

- Rust & Cargo
- Python 3.8+ with `venv`

### Setup

1. Clone the repository:

```bash
git clone <your-repo-url>
cd rust-ml-benchmark
```

2. Create and activate a Python virtual environment:

```bash
python -m venv venv
source venv/bin/activate
```

3. Install Python dependencies:

```bash
pip install pandas scikit-learn matplotlib seaborn psutil
```

### ğŸš€ Benchmark Execution

#### **One-Command (Recommended)**

```bash
# Run all benchmarks (both datasets)
./run_benchmarks.sh
```

#### **Manual Execution**

```bash
# Run single dataset benchmark
python3 scripts/benchmark_runner.py --dataset data/iris.csv --runs 5

# Run large dataset benchmark
python3 scripts/benchmark_runner.py --dataset data/bank-additional/bank-additional-full.csv --runs 3
```

## ğŸ“Š Sample Results

### ğŸŒ¼ Iris Dataset (Small - 150 samples, 4 features)

#### Support Vector Machines

| **Library** | **Algorithm** | **Training (s)** | **Inference (s)** | **Accuracy** | **Memory (MB)** |
|-------------|---------------|------------------|-------------------|--------------|-----------------|
| **scikit-learn** | SVM | 0.001716Â±nan | 0.000343Â±nan | 1.0000Â±nan | 0.39 |
| **scikit-learn** | SVM (Linear) | 0.001110Â±nan | 0.000196Â±nan | 1.0000Â±nan | 0.16 |
| **linfa** | SVM (Binary) | 0.001045Â±nan | 0.000035Â±nan | 1.0000Â±nan | 0.71 |

#### Tree-Based Models

| **Library** | **Algorithm** | **Training (s)** | **Inference (s)** | **Accuracy** | **Memory (MB)** |
|-------------|---------------|------------------|-------------------|--------------|-----------------|
| **scikit-learn** | Decision Tree | 0.000992Â±nan | 0.000135Â±nan | 1.0000Â±nan | 0.31 |
| **scikit-learn** | Random Forest | 0.083311Â±nan | 0.003076Â±nan | 1.0000Â±nan | 0.75 |
| **smartcore** | Decision Tree | 0.000120Â±nan | 0.000006Â±nan | 0.7333Â±nan | 2.22 |
| **smartcore** | Random Forest | 0.002361Â±nan | 0.000228Â±nan | 0.7333Â±nan | 1.04 |
| **linfa** | DecisionTree | 0.000107Â±nan | 0.000003Â±nan | 0.6897Â±nan | 2.12 |

#### Neural Networks

| **Library** | **Algorithm** | **Training (s)** | **Inference (s)** | **Accuracy** | **Memory (MB)** |
|-------------|---------------|------------------|-------------------|--------------|-----------------|
| **scikit-learn** | Neural Network | 0.134045Â±nan | 0.000191Â±nan | 1.0000Â±nan | 1.75 |

#### Performance Champions (Iris Dataset)

- **ğŸƒ Fastest Training**: Decision Tree (smartcore) - 0.000102s
- **âš¡ Fastest Inference**: DecisionTree (linfa) - 0.000003s
- **ğŸ¯ Best Accuracy**: SVM (Binary) (linfa) - 1.0000
- **ğŸ’¾ Most Memory Efficient**: SVM (Linear) (scikit-learn) - 0.16 MB

### ğŸ¦ Bank Dataset (Large - 41,188 samples, 20 features)

*Benchmark results will be added after running the full dataset comparison. The bank dataset is significantly larger and will provide insights into production-scale performance differences between Rust and Python ML libraries.*

#### Expected Algorithms to Test:
- **Support Vector Machines**: Linear SVM, RBF SVM
- **Tree-Based Models**: Decision Trees, Random Forests
- **Neural Networks**: Multi-layer Perceptrons

#### Expected Metrics:
- Training time (seconds)
- Inference time (seconds)
- Accuracy scores
- Memory usage (MB)
- CPU utilization (%)
- Peak memory consumption

## ğŸ“ˆ Output Files

The benchmark generates:

- **ğŸ“ `benchmark_report_*.md`**: Comprehensive markdown reports with results by algorithm category
- **ğŸ“Š `benchmark_plots_*.png`**: Performance visualizations (training time, inference time, accuracy, memory usage)
- **ğŸ“„ `benchmark_data_*.csv`**: Raw benchmark data for further analysis

## ğŸ”¬ Technical Details

### Algorithm Standardization

The benchmark standardizes algorithm names across libraries:

- **SVM variations**: `SVC`, `SVM (One-vs-Rest)`, `SVM (Binary)`, `LinearSVC` â†’ `SVM`, `SVM (Binary)`, `SVM (Linear)`
- **Tree variations**: `DecisionTreeClassifier`, `Decision Tree` â†’ `Decision Tree`
- **Forest variations**: `RandomForestClassifier`, `Random Forest` â†’ `Random Forest`
- **Neural networks**: `MLPClassifier`, `MLP` â†’ `Neural Network`

### Dataset Handling

- **Iris dataset**: Standard CSV format, last column is target
- **Bank dataset**: Semicolon-separated, categorical features encoded
- **Preprocessing**: Standard scaling for SVM/MLP, raw data for trees

### Performance Metrics

- **Training time**: Model fitting duration (seconds)
- **Inference time**: Prediction duration (seconds)
- **Accuracy**: Classification accuracy on test set
- **Memory usage**: Peak memory consumption during training (MB)

## ğŸ¯ Key Findings

### Small Dataset (Iris) - Latest Results
- **ğŸƒ Fastest training**: Decision Tree (smartcore) - 0.000102s
- **âš¡ Fastest inference**: DecisionTree (linfa) - 0.000003s
- **ğŸ¯ Best accuracy**: SVM (Binary) (linfa) - 100%
- **ğŸ’¾ Most memory efficient**: SVM (Linear) (scikit-learn) - 0.16 MB

### Large Dataset (Bank) - Coming Soon
- **Expected insights**: Production-scale performance comparison
- **Focus areas**: Training time, memory efficiency, CPU utilization
- **Target**: Understanding Rust vs Python trade-offs at scale

## Contributing

When adding new benchmarks:

1. **Keep it simple**: Focus on core ML algorithms
2. **Standardize names**: Use consistent algorithm naming
3. **Dataset-centric**: Organize by dataset size
4. **Fair comparison**: Compare same algorithms across libraries

## License

This project is licensed under the MIT License.