# Rust vs. Python for ML: A Performance Benchmark

This repository contains the source code and benchmark results for a paper evaluating the performance of Rust-based machine learning libraries against their established Python counterparts. This first phase focuses on classical machine learning algorithms.

## Results: Classical Machine Learning

The benchmarks were run on the Iris dataset. Below is a summary of the performance metrics for `scikit-learn` (Python), `linfa` (Rust), and `smartcore` (Rust).

## Performance Metrics Table

*(This table is auto-generated by `scripts/report_generator.py` and saved in `results/benchmark_table.md`)*

| **Library** | **Model** | **Training Time (s)** | **Inference Time (s)** | **Accuracy** | **Memory Usage (MB)** |
|-------------|-----------|----------------------|------------------------|--------------|----------------------|
| **linfa** | Decision Tree | 0.000131 | 0.000002 | 0.70000 | 0.0 |
| | SVM (One-vs-Rest) | 0.003103 | 0.000106 | 0.80000 | 0.25 |
| **scikit-learn** | Random Forest | 0.081000 | 0.003700 | 1.00000 | 1.1836 |
| | SVC | 0.001400 | 0.000600 | 1.00000 | 0.25 |
| | MLP | 0.120700 | 0.000700 | 0.96667 | 1.1367 |
| **smartcore** | Random Forest | 0.002472 | 0.000189 | 0.73333 | 0.375 |
| | Multi-Class SVC | 0.006000 | 0.000246 | 0.83333 | 0.25 |

## Performance Graphs

*(Performance graphs will be generated and placed here)*

## Repository Structure

```
rust-ml-benchmark/
├── data/               # Input datasets
├── results/            # Output tables, logs, and plots
├── scripts/            # All benchmark source code (Rust & Python)
├── workflow/           # Nextflow orchestration scripts (Phase 2)
└── README.md           # This file
```

## How to Run

### Prerequisites

- Rust & Cargo
- Python 3.8+ with `venv`
- `make` (optional, for convenience)

### Setup

1. Clone the repository:

```bash
git clone <your-repo-url>
cd rust-ml-benchmark
```

2. Create and activate a Python virtual environment:

```bash
python -m venv venv
source venv/bin/activate
```

3. Install Python dependencies:

```bash
pip install -r requirements.txt
```

*(Note: You may need to create a `requirements.txt` file first with `pip freeze > requirements.txt`)*

### Execution

1. To run all benchmarks and generate the report:

```bash
# Phase 1
python scripts/sklearn_bencher.py --dataset data/iris.csv --output results/sklearn_results.txt
cargo run --release --manifest-path scripts/Cargo.toml --package linfa_bencher -- --dataset data/iris.csv --output results/linfa_results.txt
cargo run --release --manifest-path scripts/Cargo.toml --package smartcore_bencher -- --dataset data/iris.csv --output results/smartcore_results.txt

# Generate all tables and plots
python scripts/report_generator.py
```